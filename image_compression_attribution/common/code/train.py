"""Train models of compression settings from news sources"""
import os
import argparse
import logging
import pickle
import numpy as np
import pandas as pd

from image_compression_attribution.common.code.models.compr_levels import read_compression_level, attribution_compression_levels


#Sources to include if you train a model.
#(This list exists to allow you to include only a subset of available sources
#when you train a model.)
NEWS_SOURCES_TO_INCLUDE_IN_MODEL = ['abc.net.au',
 'airforcetimes.com',
 'aljazeera',
 'allafrica.com',
 'americanfreepress',
 'asahi.com',
 'bbc',
 'canadiandimension',
 'ceasefire',
 'centurywire',
 'egypttoday',
 'france24',
 'ghanaiantimes.com.gh',
 'globaltimes',
 'hindustantimes.com',
 'japantimes.co.jp',
 'koreatimes.co.kr',
 'militarytimes.com',
 'navytimes.com',
 'nst',
 'oneindia.com',
 'rferl',
 'russiatoday',
 'sbs.com.au',
 'straitstimes',
 'taipeitimes',
 'thestar.com',
 'timesofindia',
 'trtworld',
 'voanews']


def train_model(summary_file, model_file=None):
  """Fit model (using entire dataset)

  The model trained with this code uses compression levels (only) as
  features. It does not include quantization matrices or file formats.

  Args:
    summary_file: string, path to pickle file that summarizes input data
      (as generated by function summarize_compression_levels )
    model_file: string or None; path of pickle file to generate storing
      generated model. If none, skip saving model.

  Returns:
    acl:  attribution_compression_levels model that was fit on the data
    df: dataframe used for training
    df_dropped: dataframe with dropped rows
  """

  df = pd.read_pickle(summary_file)

  #Filter images using file MIME type:
  #Drop non-image files, e.g. drop html files returned
  #due to download errors.

  df, df_dropped = df[ df['mime'].str.startswith('image') ].reset_index(drop=True), \
    df[ ~df['mime'].str.startswith('image') ].reset_index(drop=True)

  #Train on entire dataset
  df_train = df

  df_train = df_train[df_train['source'].isin(NEWS_SOURCES_TO_INCLUDE_IN_MODEL)]
  df_train.reset_index(drop=True, inplace=True)

  acl = attribution_compression_levels()
  acl.fit(df_train)

  if model_file is not None:
    with open(model_file, 'wb') as f:
      pickle.dump(acl, f)

  return acl, df, df_dropped


if __name__ == "__main__":

  parser = argparse.ArgumentParser(description=
    'Train model on image data.',
    formatter_class=argparse.ArgumentDefaultsHelpFormatter)
  
  parser.add_argument("-i", "--in_file", type=str, 
    default="data/news_images/processed/summary-compression-levels.pkl",
    help="Input pickle file that summarizes dataset")

  parser.add_argument("-o", "--out_file", type=str, 
    default="models/compr_levels_nb_v1.pkl",
    help="Path to output model file to generate")

  args = parser.parse_args()
  
  logging.debug("About to train model using compression level features")

  train_model(args.in_file, args.out_file)

  logging.debug("Model saved in {}".format(args.out_file))